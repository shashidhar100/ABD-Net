{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b9ca9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0310cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset_path = os.path.join(\"..\",\"Datasets\",\"TRACEPARTS_DATA\")\n",
    "\n",
    "# dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68125323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_path_train = os.path.join(dataset_path,\"train_test_split/clean_shuffled_train_file_list.json\")\n",
    "# json_path_val = os.path.join(dataset_path,\"train_test_split/clean_shuffled_val_file_list.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc6964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_train = pd.read_json(json_path_train)\n",
    "# json_val = pd.read_json(json_path_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c657ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_train = json_train.replace(to_replace=r\"^shape_data\",value=dataset_path,inplace=False,regex=True) + \".txt\" \n",
    "# json_val = json_val.replace(to_replace=r\"^shape_data\",value=dataset_path,inplace=False,regex=True)+\".txt\"\n",
    "# json_train.to_csv(os.path.join(dataset_path,\"train.csv\"),index=None)\n",
    "# json_val.to_csv(os.path.join(dataset_path,\"validation.csv\"),index=None)\n",
    "# train = pd.read_csv(os.path.join(dataset_path,\"train.csv\"))\n",
    "# list(train[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad205408",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraceParts_Dataloader(Dataset):\n",
    "    def __init__(self,sample_points=1024, split='train', normalize=True, cache_size=150,uniform=True,normals=True):\n",
    "        self.sample_points = sample_points\n",
    "        self.split = split\n",
    "        self.normalize = normalize\n",
    "        self.cache_size = cache_size\n",
    "        self.uniform = uniform\n",
    "        self.normals = normals\n",
    "        self.dataset_path = os.path.join(\"..\",\"Datasets\",\"TRACEPARTS_DATA\")\n",
    "        train_path = os.path.join(self.dataset_path,\"train.csv\")\n",
    "        val_path = os.path.join(self.dataset_path,\"validation.csv\")\n",
    "        self.train_files = list(pd.read_csv(train_path)[\"0\"])\n",
    "        self.val_files = list(pd.read_csv(val_path)[\"0\"])\n",
    "        self.split_dic = {\"train\":self.train_files,\"val\":self.val_files}\n",
    "        self.cache = {}\n",
    "    \n",
    "    \n",
    "    def pc_normalize(self,pc):\n",
    "        centroid = np.mean(pc, axis=0)\n",
    "        pc = pc - centroid\n",
    "        m = np.max(np.sqrt(np.sum(pc**2, axis=1)))\n",
    "        pc = pc / m\n",
    "        return pc\n",
    "    \n",
    "    def farthest_point_sample(self,point,label,npoint):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz: pointcloud data, [N, D]\n",
    "            label : per point label ,[N]\n",
    "            npoint: number of samples\n",
    "        Return:\n",
    "            centroids: sampled pointcloud index, [npoint, D]\n",
    "        \"\"\"\n",
    "        N, D = point.shape\n",
    "        xyz = point[:,:3]\n",
    "        centroids = np.zeros((npoint,))\n",
    "        distance = np.ones((N,)) * 1e10\n",
    "        farthest = np.random.randint(0, N)\n",
    "        for i in range(npoint):\n",
    "            centroids[i] = farthest\n",
    "            centroid = xyz[farthest, :]\n",
    "            dist = np.sum((xyz - centroid) ** 2, -1)\n",
    "            mask = dist < distance\n",
    "            distance[mask] = dist[mask]\n",
    "            farthest = np.argmax(distance, -1)\n",
    "        point = point[centroids.astype(np.int32)]\n",
    "        label = label[centroids.astype(np.int32)]\n",
    "        return point,label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.split_dic[self.split])\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        if index in self.cache:\n",
    "            return self.cache[index][0],self.cache[index][1]\n",
    "        else:\n",
    "            file = np.loadtxt(self.split_dic[self.split][index])\n",
    "            if self.normals:\n",
    "                pc,label = file[0:-1],file[:,-1]\n",
    "            else:\n",
    "                pc,label = file[0:3],file[:,-1]\n",
    "            \n",
    "            if self.uniform:\n",
    "                pc,label = self.farthest_point_sample(pc,label,self.sample_points)\n",
    "            else:\n",
    "                pc,label = pc[0:self.sample_points,:],label[0:self.sample_points]\n",
    "            \n",
    "            if len(self.cache) < self.cache_size:\n",
    "                self.cache[index] = (pc, label)\n",
    "            \n",
    "            return pc,label\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529fed01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1024, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((16,1024,3))\n",
    "dis = torch.cdist(x,x)\n",
    "dis.shape\n",
    "ne = dis.topk(dim=2,k=32,largest=False)\n",
    "ne.indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e96c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "02800da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_ply(name,pc,center,idx):\n",
    "    #pred = np.asarray(pred.cpu())\n",
    "    # pred = np.ones((pc.shape[0],1))*3\n",
    "    #pc = np.asarray(pc.cpu())\n",
    "    # pred = pred.reshape(pred.shape[0],1)\n",
    "    file = open(name+\".ply\",'w')\n",
    "    n_verts = pc.shape[0]\n",
    "    file.write(\"ply\\nformat ascii 1.0\\nelement vertex \"+str(n_verts)+\"\\nproperty float x\\nproperty float y\\nproperty float z\\nproperty uchar red\\nproperty uchar green\\nproperty uchar blue\\nend_header\\n\")\n",
    "    color_map = {0:\"0 0 0\", 1:\"0 0 255\", 2:\"255 0 255\", 3:\"0 255 0\"}\n",
    "    # encode_pred = ''\n",
    "    file.write(str(center[0])+\" \"+str(center[1])+\" \"+str(center[2])+\" \"+\"0 255 0\\n\")\n",
    "#     print(idx)\n",
    "    for i in range(pc.shape[0]):\n",
    "        ek = str(pc[i][0])\n",
    "        do = str(pc[i][1])\n",
    "        ten = str(pc[i][2])\n",
    "        #char = str(pc[i][3])\n",
    "        #pan = str(pc[i][4])\n",
    "        #she = str(pc[i][5])\n",
    "        if pc[i] in idx:\n",
    "            rgb = color_map[2]\n",
    "        else:\n",
    "            rgb = \"0 0 0\"\n",
    "        #file.write(ek+\" \"+do+\" \"+ten+\" \"+char+\" \"+pan+\" \"+she+\" \"+rgb+'\\n')\n",
    "        file.write(ek+\" \"+do+\" \"+ten+\" \"+rgb+'\\n')\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f6bd5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "j = 100\n",
    "save_as_ply(\"test\",pc[i,:,:3].numpy(),pc[i,j,:3].numpy(),c[i,j,:,:3].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234fd271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Time Taken : 0.2815415859222412\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_as_ply' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f23fabf9c38c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time Taken :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     print(neighbors.indices[0][0][:].numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msave_as_ply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0msave_as_ply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msave_as_ply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_as_ply' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = TraceParts_Dataloader(split=\"val\")\n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=16,shuffle=True)\n",
    "cuda = torch.device('cuda')\n",
    "import time\n",
    "for batch,(pc,label) in enumerate(train_loader):\n",
    "    print(batch)\n",
    "#     pc.cuda()\n",
    "    s_t = time.time()\n",
    "    dis = torch.cdist(pc[:,:,:3],pc[:,:,:3])\n",
    "    neighbors = dis.topk(dim=2,k=32,largest=False)\n",
    "#     pc_with_neighbors = torch.gather(pc,1,neighbors.indices)\n",
    "#     print(pc_with_neighbors.shape)\n",
    "    print(\"Time Taken :\",time.time()-s_t)\n",
    "#     print(neighbors.indices[0][0][:].numpy())\n",
    "    save_as_ply(str(batch)+\"_0\",pc[0,:,:3].numpy(),pc[0][0][:3].numpy(),neighbors.indices[0][0][:].numpy())\n",
    "    save_as_ply(str(batch)+\"_1\",pc[1,:,:3].numpy(),pc[1][0][:3].numpy(),neighbors.indices[1][0][:].numpy())\n",
    "    save_as_ply(str(batch)+\"_2\",pc[2,:,:3].numpy(),pc[2][0][:3].numpy(),neighbors.indices[2][0][:].numpy())\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ccc5e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1024, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c8d650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(pc,n_neighbors=32):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        pc : Point cloud (B,N,d) knn is computed in the d dimension eculidean spcae with the euclidean distance\n",
    "        n_neighbors : Number of neighbors to find default is 32\n",
    "    Return:\n",
    "        indices of the n_neighbors for each point (B,N,n_neighbors)\n",
    "    \"\"\"\n",
    "\n",
    "    dist = torch.cdist(pc,pc)\n",
    "    neigbhors = dist.topk(k=n_neighbors,dim=2,largest=False)\n",
    "    return neigbhors.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b00ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S]\n",
    "    Return:\n",
    "        new_points:, indexed points data, [B, S, C]\n",
    "    \"\"\"\n",
    "    device = points.device\n",
    "    B = points.shape[0]\n",
    "    view_shape = list(idx.shape)\n",
    "    print(view_shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    print(view_shape)\n",
    "    repeat_shape = list(idx.shape)\n",
    "    repeat_shape[0] = 1\n",
    "    print(repeat_shape)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "    print(batch_indices[0].shape)\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5220c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_idx = knn(pc[:,:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8809459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 1024, 32]\n",
      "[16, 1, 1]\n",
      "[1, 1024, 32]\n",
      "torch.Size([1024, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1024, 32, 7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pc = index_points(pc,knn_idx)\n",
    "knn_pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bfa32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_norm(points,group_points):\n",
    "    B,S,K,D = points.size()\n",
    "    group_points_norm = group_points - points.view(B,S,1,D)\n",
    "    return group_points_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "708ebe07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1024, 32, 7])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = group_norm(pc,knn_pc)\n",
    "# mod_pc = torch.cat((grouped,knn_pc[:,:,:,3:]),dim=3)\n",
    "# print(mod_pc.shape)\n",
    "grouped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c9ef81d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]]\n",
      "(2, 2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [1]],\n",
       "\n",
       "       [[1],\n",
       "        [1]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "z = np.array([[0,0],[0,0]])\n",
    "m = np.array([[0],[0]])\n",
    "x[z,m,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c16b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 1024, 32]\n",
      "[16, 1, 1]\n",
      "[1, 1024, 32]\n",
      "torch.Size([1024, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1024, 32, 7])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = index_points(pc,neighbors.indices)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ed713",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "feef0915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0][0][:,0:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b92cd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1024, 7])\n",
      "torch.Size([16, 1024, 32])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cat(): argument 'tensors' (position 1) must be tuple of Tensors, not generator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b03738ddc06e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cat(): argument 'tensors' (position 1) must be tuple of Tensors, not generator"
     ]
    }
   ],
   "source": [
    "print(pc.shape)\n",
    "print(neighbors.indices.shape)\n",
    "pc[0,:,:][neighbors.indices[0,:,:]].shape\n",
    "torch.cat(pc[i,:,:][neighbors.indices[i,:,:]] for i in range(pc.shape[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7b1d23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors.indices[-1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24373f3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e669c1bd1b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "pu = torch.gather(pc,-1,neighbors.indices.unsqueeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b59b8f51",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index_select(): Index is supposed to be a vector",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-85fc0a191bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index_select(): Index is supposed to be a vector"
     ]
    }
   ],
   "source": [
    "torch.index_select(pc,1,neighbors.indices.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15ae050c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[16, 1024, 1, 32]}, size=[16, 1024, 7]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-5945fd6ec0f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[16, 1024, 1, 32]}, size=[16, 1024, 7]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)"
     ]
    }
   ],
   "source": [
    "ind = torch.randn((16,1024,32))\n",
    "data = torch.randn((16,1024,7))\n",
    "ind.unsqueeze(2).expand(ind.size(0),ind.size(1),data.size(2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4455bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = TraceParts_Dataloader(split=\"val\")\n",
    "# train_loader = torch.utils.data.DataLoader(train_data,batch_size=1,shuffle=True)\n",
    "# print(len(train_loader))\n",
    "# cuda = torch.device('cuda')\n",
    "# import time\n",
    "# import cudf\n",
    "# from cuml.neighbors import KNeighborsClassifier as cuKNeighbors\n",
    "# for batch,(pc,label) in enumerate(train_loader):\n",
    "#     print(batch)\n",
    "#     s_t = time.time()\n",
    "#     pc = torch.squeeze(pc,dim=0).numpy()\n",
    "# #     pc = cudf.DataFrame(pc)\n",
    "# #     label = cudf.DataFrame(label.numpy())\n",
    "# #     print(label.shape)\n",
    "#     label = label.numpy()\n",
    "#     model = cuKNeighbors(n_neighbors=32)\n",
    "#     model.fit(pc,label)\n",
    "#     knn = model.predict(pc)\n",
    "#     print(\"Time Taken :\",time.time()-s_t)\n",
    "#     print(knn)\n",
    "    \n",
    "    \n",
    "# #     print(\"B : {}, pc shape : {}, label shape : {}\".format(batch,pc.shape,label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70576316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c77b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
